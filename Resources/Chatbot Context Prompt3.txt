Acting as an expert in prompting large language models, please revise this prompt to optimize its effectiveness in producing the desired result when it is used to prompt a large language model such as GPT-3 (note that neither the usage pattern nor the psuedocode are included in the prompt. They will be added after you revise it):

Context:
	We are building a chatbot using Python and the advanced OpenAI language model, GPT-4. As an AI coding assistant with expertise in software development and machine learning, you will assist me, a new developer with limited knowledge, in this project. The chatbot will allow users to upload one or more documents, initially in .docx format, and later in other formats. The application will divide the document into smaller chunks, generate embeddings for each chunk, and store them in the vector database. This data will serve as the source from which the LLM gathers information and respond to user queries. Once the content is processed and ready, users can engage in a chat conversation with the LLM via the chatbot on topics covered in the uploaded documents, allowing the LLM to provide accurate answers based on the referenced documents. The chatbot has the following characteristics: The chatbot aims to provide a user-friendly interface for accessing and retrieving information from large text sources through semantic search. The GPT-4 language model will synthesize search results and provide accurate answers to user queries. The user base will consist of anyone needing to access and retrieve information from large bodies of text. Pinecone, a vector database product, will be used as our vector database and semantic search engine. Pinecone's capabilities include the following: Efficient storage and retrieval of high-dimensional vectors; Support for various vector operations, including similarity search, nearest neighbor search, and range search; Simple API for querying vectors and straightforward setup process; Capacity to store metadata associated with vectors in a structured format. The chatbot will have two primary integrated user interfaces arrange as tabs in a Tkinter window - one tab for uploading documentation and another tab for chatting with the LLM. Pinecone will store the vector data and SQLite will store raw text. The application will leverage two leading GitHub repositories for constructing LLM-based chatbots, LlamaIndex and LangChain.

Task:
	Below is a description of the general usage pattern for LlamaIndex and the pseudocode design for our chatbot application.  Please review the usage pattern and use the concepts included to refine our chatbot design by updating the psuedocode.

Constraints:
	Any elements you add to the design based on the usage pattern must be located correctly within the architectural structure we devised to preserve the architectural patterns we identified as optimal, but the internal logic should be refined to align with the usage pattern. 
	Please identify anywhere there is a conflict between the two or where we need additional information before we can complete the design with a comment at the relevant point in the pseudocode.
	Please identify any elements you add from the usage pattern by appending a "# LI UP" comment to the line
	If you decide to that any elements of the current design should be removed, please just comment them out with multi-line comments